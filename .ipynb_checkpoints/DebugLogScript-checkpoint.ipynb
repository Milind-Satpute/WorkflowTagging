{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38dcfe82",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3234043238.py, line 112)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 112\u001b[1;36m\u001b[0m\n\u001b[1;33m    for index, row in LogsDataSetDF['logs']..iterrows():\u001b[0m\n\u001b[1;37m                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Nov  5 15:56:13 2023\n",
    "\n",
    "@author: satpum\n",
    "\"\"\"\n",
    "\n",
    "import json;\n",
    "import pandas as pd\n",
    "import time \n",
    "import os, shutil\n",
    "from bs4 import BeautifulSoup \n",
    "import requests \n",
    "import re\n",
    "\n",
    "\n",
    "print('===============IMPORTING DATA====================')\n",
    "directoryName='./Data/Input/ge2/Es_SideCar_Logs_ge2.json'\n",
    "if not os.path.exists(directoryName):\n",
    "   os.makedirs(directoryName)\n",
    "\n",
    "\n",
    "print('=======Getting Data From '+directoryName+'============')\n",
    "\n",
    "f1  = open(directoryName, encoding=\"utf8\")\n",
    "\n",
    "\n",
    "dataSideCarLogs = json.load(f1)\n",
    "#os.close(f1)\n",
    "\n",
    "sourceArray=[]\n",
    "sidecarDataFrame= pd.DataFrame(dataSideCarLogs,columns = ['_source'])\n",
    "sourceArrayDataFrame= pd.DataFrame(sidecarDataFrame['_source'])\n",
    "#sourceArrayDataFrame['_source'].to_json('./Data/Input/ge2/Data2.json',orient='records')\n",
    "#print(sourceArrayDataFrame)\n",
    "\n",
    "log_processed=[]\n",
    "for row in sourceArrayDataFrame['_source']:\n",
    "    log_processed.append(row)\n",
    "#print(log_processed)    \n",
    "\n",
    "\n",
    "\n",
    "logprocessedDF= pd.DataFrame(log_processed,columns=['log_processed'])\n",
    "\n",
    "#print(logprocessedDF)\n",
    "\n",
    "\n",
    "logArray=[]\n",
    "for log in logprocessedDF['log_processed']:\n",
    "    logArray.append(log)\n",
    "\n",
    "logsDF=pd.DataFrame(logArray,columns=['dpid','message','domain'])\n",
    "\n",
    "\n",
    "print('===============READING HITS ====================')\n",
    "\n",
    "\n",
    "#logsDF=pd.DataFrame(logs,columns=['dpid','message','domain']) \n",
    "#print(logsDF.head(2))\n",
    "uniquiDpid=[]\n",
    "uniquiDpid=logsDF['dpid'].unique();\n",
    "\n",
    "print('============Saving logs in Dpid Name file ===============')\n",
    "message=[]\n",
    "\n",
    "#print(logsDF[(logsDF['dpid']=='7020000346408')]['message'])\n",
    "\n",
    "for dpid in uniquiDpid:\n",
    "    fileName=dpid+'.json'\n",
    "    if not os.path.exists('./Data/Output/Final/Dpids'):\n",
    "       os.makedirs('./Data/Output/Final/Dpids')\n",
    "    pathName='./Data/Output/Final/Dpids/'+fileName\n",
    "    series=logsDF[(logsDF['dpid']==dpid)]['message']\n",
    "    #print(type(series))\n",
    "    pdf=series.to_frame()\n",
    "#    pdf=pdf.rename(columns = {0:'message'})\n",
    "    pdf['message'].to_json(pathName,orient='records')\n",
    "    #logsDF[(logsDF['dpid']==dpid)]['message'].to_json(pathName)\n",
    "    #print('===saving file at '+pathName) \n",
    "\n",
    "\n",
    "\n",
    "print('============Creating Data Set ===============')\n",
    "\n",
    "uniquiDpid=[]\n",
    "uniquiDpid=logsDF['dpid'].unique();\n",
    "\n",
    "message=''\n",
    "messageArray=[]\n",
    "for dpid in uniquiDpid:\n",
    "    fileName=dpid+'.json'\n",
    "    directoryName='./Data/Output/Final/Dpids/'+fileName\n",
    "    print('=======Getting Data From '+directoryName+'============')\n",
    "    f1  = open(directoryName, encoding=\"utf8\")\n",
    "    logs = json.load(f1)\n",
    "    logsDF=pd.DataFrame(logs,columns=['logs'])\n",
    "    #print(logsDF)\n",
    "\n",
    "    logarray=[]\n",
    "    for index, row in logsDF.iterrows():\n",
    "        #print(row)\n",
    "        message=message +row;\n",
    "    messageArray.append(message)\n",
    "    print(len(messageArray))\n",
    "\n",
    "\n",
    "print('============Done creating MessageArray ===============')\n",
    "\n",
    "LogsDataSetDF=pd.DataFrame(messageArray)\n",
    "\n",
    "for index, row in LogsDataSetDF['logs'].iterrows():\n",
    "    print(row)\n",
    "    \n",
    "\n",
    "#text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "\n",
    "print('============Saving DataSet ===============')\n",
    "    \n",
    "pathName='./Data/Output/final/DataSet/'    \n",
    "\n",
    "if not os.path.exists(pathName): \n",
    "    os.makedirs(pathName)\n",
    "\n",
    "fileName='Final_Log_DataSet'+ time.strftime(\"%Y%m%d-%H%M%S\")+'.json'\n",
    "LogsDataSetDF.to_json(pathName+fileName,orient='records')\n",
    "print(os.path.abspath(pathName+fileName))\n",
    "\n",
    "print('============Saving DataSet at '+fileName+'====================')\n",
    "print('============Finish Saving DataSet ===============')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea67cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogsDataSetDF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m LogsDataSetDF[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(message)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogsDataSetDF' is not defined"
     ]
    }
   ],
   "source": [
    "print('============Deleting Dpid Files  ===============')\n",
    "\n",
    "folder = './Data/Output/Final/Dpids/'\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117f5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
